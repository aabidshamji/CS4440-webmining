{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# CS 4440 - Amazon dataset embeddings\n",
    "# Adapted from https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  10815\n",
      "Number of columns:  11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>image</th>\n",
       "      <th>brand</th>\n",
       "      <th>details</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>also_view</th>\n",
       "      <th>rank</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Sink your sweet tooth into MILK DUDS Candya d...</td>\n",
       "      <td>HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...</td>\n",
       "      <td>[B019KE37WO, B007NQSWEU]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>Milk Duds</td>\n",
       "      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n",
       "      <td>$5.00</td>\n",
       "      <td>B00005BPJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Sink your sweet tooth into MILK DUDS Candya d...</td>\n",
       "      <td>HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...</td>\n",
       "      <td>[B019KE37WO, B007NQSWEU]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>Milk Duds</td>\n",
       "      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n",
       "      <td>$5.00</td>\n",
       "      <td>B00005BPJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[A perfect Lentil soup starts with Goya Lentil...</td>\n",
       "      <td>Goya Dry Lentils, 16 oz</td>\n",
       "      <td>[B003SI144W, B000VDRKEK]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>Goya</td>\n",
       "      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B0000DIF38</td>\n",
       "      <td>[B074MFVZG7, B079PTH69L, B000VDRKEK, B074M9T81...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Saran Premium Wrap is an extra tough yet easy...</td>\n",
       "      <td>Saran Premium Plastic Wrap, 100 Sq Ft</td>\n",
       "      <td>[B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>Saran</td>\n",
       "      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>[B077QLSLRQ, B00JPKW1RQ, B000FE2IK6, B00XUJHJ9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[200 sq ft (285 ft x 11-3/4 in x 18.6 m2). Eas...</td>\n",
       "      <td>Saran Cling Plus Plastic Wrap, 200 Sq Ft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>Saran</td>\n",
       "      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B0000DIWNZ</td>\n",
       "      <td>[B0014CZ0TE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  [Sink your sweet tooth into MILK DUDS Candya d...   \n",
       "1  [Sink your sweet tooth into MILK DUDS Candya d...   \n",
       "2  [A perfect Lentil soup starts with Goya Lentil...   \n",
       "3  [Saran Premium Wrap is an extra tough yet easy...   \n",
       "4  [200 sq ft (285 ft x 11-3/4 in x 18.6 m2). Eas...   \n",
       "\n",
       "                                               title  \\\n",
       "0  HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...   \n",
       "1  HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...   \n",
       "2                            Goya Dry Lentils, 16 oz   \n",
       "3              Saran Premium Plastic Wrap, 100 Sq Ft   \n",
       "4           Saran Cling Plus Plastic Wrap, 200 Sq Ft   \n",
       "\n",
       "                                            also_buy  \\\n",
       "0                           [B019KE37WO, B007NQSWEU]   \n",
       "1                           [B019KE37WO, B007NQSWEU]   \n",
       "2                           [B003SI144W, B000VDRKEK]   \n",
       "3  [B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               image      brand  \\\n",
       "0  [https://images-na.ssl-images-amazon.com/image...  Milk Duds   \n",
       "1  [https://images-na.ssl-images-amazon.com/image...  Milk Duds   \n",
       "2  [https://images-na.ssl-images-amazon.com/image...       Goya   \n",
       "3  [https://images-na.ssl-images-amazon.com/image...      Saran   \n",
       "4  [https://images-na.ssl-images-amazon.com/image...      Saran   \n",
       "\n",
       "                                             details  price        asin  \\\n",
       "0  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...  $5.00  B00005BPJO   \n",
       "1  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...  $5.00  B00005BPJO   \n",
       "2  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...    NaN  B0000DIF38   \n",
       "3  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...    NaN  B0000DIWNI   \n",
       "4  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...    NaN  B0000DIWNZ   \n",
       "\n",
       "                                           also_view rank feature  \n",
       "0                                                NaN  NaN     NaN  \n",
       "1                                                NaN  NaN     NaN  \n",
       "2  [B074MFVZG7, B079PTH69L, B000VDRKEK, B074M9T81...  NaN     NaN  \n",
       "3  [B077QLSLRQ, B00JPKW1RQ, B000FE2IK6, B00XUJHJ9...  NaN     NaN  \n",
       "4                                       [B0014CZ0TE]  NaN     NaN  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = getDF('meta_Prime_Pantry.json.gz')\n",
    "rows,columns=meta_df.shape\n",
    "print('Number of rows: ',rows)\n",
    "print('Number of columns: ',columns)\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique product in Raw data =  10814\n"
     ]
    }
   ],
   "source": [
    "#Number of unique user id  in the data\n",
    "print('Number of unique product in Raw data = ', meta_df['asin'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = meta_df[['asin', 'also_buy', 'also_view', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>also_view</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B00005BPJO</td>\n",
       "      <td>[B019KE37WO, B007NQSWEU]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B00005BPJO</td>\n",
       "      <td>[B019KE37WO, B007NQSWEU]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B0000DIF38</td>\n",
       "      <td>[B003SI144W, B000VDRKEK]</td>\n",
       "      <td>[B074MFVZG7, B079PTH69L, B000VDRKEK, B074M9T81...</td>\n",
       "      <td>Goya Dry Lentils, 16 oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>[B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...</td>\n",
       "      <td>[B077QLSLRQ, B00JPKW1RQ, B000FE2IK6, B00XUJHJ9...</td>\n",
       "      <td>Saran Premium Plastic Wrap, 100 Sq Ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B0000DIWNZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[B0014CZ0TE]</td>\n",
       "      <td>Saran Cling Plus Plastic Wrap, 200 Sq Ft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                           also_buy  \\\n",
       "0  B00005BPJO                           [B019KE37WO, B007NQSWEU]   \n",
       "1  B00005BPJO                           [B019KE37WO, B007NQSWEU]   \n",
       "2  B0000DIF38                           [B003SI144W, B000VDRKEK]   \n",
       "3  B0000DIWNI  [B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...   \n",
       "4  B0000DIWNZ                                                NaN   \n",
       "\n",
       "                                           also_view  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [B074MFVZG7, B079PTH69L, B000VDRKEK, B074M9T81...   \n",
       "3  [B077QLSLRQ, B00JPKW1RQ, B000FE2IK6, B00XUJHJ9...   \n",
       "4                                       [B0014CZ0TE]   \n",
       "\n",
       "                                               title  \n",
       "0  HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...  \n",
       "1  HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...  \n",
       "2                            Goya Dry Lentils, 16 oz  \n",
       "3              Saran Premium Plastic Wrap, 100 Sq Ft  \n",
       "4           Saran Cling Plus Plastic Wrap, 200 Sq Ft  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove asin if also_buy and also_view are both NaN\n",
    "df = df.dropna(subset=['also_buy', 'also_view'], how='all')\n",
    "\n",
    "#Remove duplicates asin\n",
    "df.drop_duplicates(subset =\"asin\", keep = 'first', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7784, 4)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['also_buy'].isnull(),['also_buy']] = df.loc[df['also_buy'].isnull(),'also_buy'].apply(lambda x: [])\n",
    "df.loc[df['also_view'].isnull(),['also_view']] = df.loc[df['also_view'].isnull(),'also_view'].apply(lambda x: [])\n",
    "df['buy_and_view'] = df['also_buy'] + df['also_view']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>also_view</th>\n",
       "      <th>title</th>\n",
       "      <th>buy_and_view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B00005BPJO</td>\n",
       "      <td>[B019KE37WO, B007NQSWEU]</td>\n",
       "      <td>[]</td>\n",
       "      <td>HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...</td>\n",
       "      <td>[B019KE37WO, B007NQSWEU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B0000DIF38</td>\n",
       "      <td>[B003SI144W, B000VDRKEK]</td>\n",
       "      <td>[B074MFVZG7, B079PTH69L, B000VDRKEK, B074M9T81...</td>\n",
       "      <td>Goya Dry Lentils, 16 oz</td>\n",
       "      <td>[B003SI144W, B000VDRKEK, B074MFVZG7, B079PTH69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>[B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...</td>\n",
       "      <td>[B077QLSLRQ, B00JPKW1RQ, B000FE2IK6, B00XUJHJ9...</td>\n",
       "      <td>Saran Premium Plastic Wrap, 100 Sq Ft</td>\n",
       "      <td>[B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B0000DIWNZ</td>\n",
       "      <td>[]</td>\n",
       "      <td>[B0014CZ0TE]</td>\n",
       "      <td>Saran Cling Plus Plastic Wrap, 200 Sq Ft</td>\n",
       "      <td>[B0014CZ0TE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>B0000GH6UG</td>\n",
       "      <td>[B008MHKWLK]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ibarra Mexican Chocolate, 19 oz</td>\n",
       "      <td>[B008MHKWLK]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                           also_buy  \\\n",
       "0  B00005BPJO                           [B019KE37WO, B007NQSWEU]   \n",
       "2  B0000DIF38                           [B003SI144W, B000VDRKEK]   \n",
       "3  B0000DIWNI  [B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...   \n",
       "4  B0000DIWNZ                                                 []   \n",
       "5  B0000GH6UG                                       [B008MHKWLK]   \n",
       "\n",
       "                                           also_view  \\\n",
       "0                                                 []   \n",
       "2  [B074MFVZG7, B079PTH69L, B000VDRKEK, B074M9T81...   \n",
       "3  [B077QLSLRQ, B00JPKW1RQ, B000FE2IK6, B00XUJHJ9...   \n",
       "4                                       [B0014CZ0TE]   \n",
       "5                                                 []   \n",
       "\n",
       "                                               title  \\\n",
       "0  HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween C...   \n",
       "2                            Goya Dry Lentils, 16 oz   \n",
       "3              Saran Premium Plastic Wrap, 100 Sq Ft   \n",
       "4           Saran Cling Plus Plastic Wrap, 200 Sq Ft   \n",
       "5                    Ibarra Mexican Chocolate, 19 oz   \n",
       "\n",
       "                                        buy_and_view  \n",
       "0                           [B019KE37WO, B007NQSWEU]  \n",
       "2  [B003SI144W, B000VDRKEK, B074MFVZG7, B079PTH69...  \n",
       "3  [B01MY5FHT6, B000PYF8VM, B000SRMDFA, B07CX6LN8...  \n",
       "4                                       [B0014CZ0TE]  \n",
       "5                                       [B008MHKWLK]  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of asin to index and index to asin\n",
    "asin_index = {}\n",
    "index_asin = {}\n",
    "\n",
    "for i, a in enumerate(df['asin']):\n",
    "    asin_index[a] = i\n",
    "    index_asin[i] = a\n",
    "\n",
    "link_index = {}\n",
    "index_link = {}\n",
    "index = 0 \n",
    "# add the asin for buy_and_view\n",
    "for link_arr in df['buy_and_view']:\n",
    "    for link in link_arr:\n",
    "        if link not in link_index:\n",
    "            link_index[link] = index\n",
    "            index_link[index] = link\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "asin_name = {}\n",
    "for index, row in df.iterrows():\n",
    "    asinp = row['asin']\n",
    "    namep = row['title']\n",
    "    asin_name[asinp] = namep\n",
    "    for link in row['buy_and_view']:\n",
    "        pairs.append((asin_index[row['asin']], link_index[link]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(100)\n",
    "\n",
    "def generate_batch(pairs, n_positive = 50, negative_ratio = 1.0, classification = False):\n",
    "    \"\"\"Generate batches of samples for training\"\"\"\n",
    "    batch_size = n_positive * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    pairs_set = set(pairs)\n",
    "    \n",
    "    # Adjust label based on task\n",
    "    if classification:\n",
    "        neg_label = 0\n",
    "    else:\n",
    "        neg_label = -1\n",
    "    \n",
    "    # This creates a generator\n",
    "    while True:\n",
    "        # randomly choose positive examples\n",
    "        for idx, (asin_id, link_id) in enumerate(random.sample(pairs, n_positive)):\n",
    "            batch[idx, :] = (asin_id, link_id, 1)\n",
    "\n",
    "        # Increment idx by 1\n",
    "        idx += 1\n",
    "        \n",
    "        # Add negative examples until reach batch size\n",
    "        while idx < batch_size:\n",
    "            \n",
    "            # random selection\n",
    "            random_asin = random.randrange(len(asin_index))\n",
    "            random_link = random.randrange(len(link_index))\n",
    "            \n",
    "            # Check to make sure this is not a positive example\n",
    "            if (random_asin, random_link) not in pairs_set:\n",
    "                \n",
    "                # Add to batch and increment index\n",
    "                batch[idx, :] = (random_asin, random_link, neg_label)\n",
    "                idx += 1\n",
    "                \n",
    "        # Make sure to shuffle order\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'asin': batch[:, 0], 'link': batch[:, 1]}, batch[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'asin': array([2224., 3219., 2865., 1431., 3726., 6274.]),\n",
       "  'link': array([ 3671., 11992.,  7102., 11559., 12628.,  8076.])},\n",
       " array([ 1., -1., -1., -1., -1.,  1.]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generate_batch(pairs, n_positive = 2, negative_ratio = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model\n",
    "def embedding_model(embedding_size = 50, classification = False):\n",
    "    \"\"\"Model to embed item and link using the Keras functional API.\n",
    "       Trained to discern if another product is in the corresponding list\"\"\"\n",
    "    \n",
    "    # Both inputs are 1-dimensional\n",
    "    asin = Input(name = 'asin', shape = [1])\n",
    "    link = Input(name = 'link', shape = [1])\n",
    "    \n",
    "    # Embedding the asin (shape will be (None, 1, 50))\n",
    "    asin_embedding = Embedding(name = 'asin_embedding',\n",
    "                               input_dim = len(asin_index),\n",
    "                               output_dim = embedding_size)(asin)\n",
    "    \n",
    "    # Embedding the link (shape will be (None, 1, 50))\n",
    "    link_embedding = Embedding(name = 'link_embedding',\n",
    "                               input_dim = len(link_index),\n",
    "                               output_dim = embedding_size)(link)\n",
    "    \n",
    "    # Merge the layers with a dot product along the second axis \n",
    "    # (shape will be (None, 1, 1))\n",
    "    merged = Dot(name = 'dot_product', normalize = True, \n",
    "                 axes = 2)([asin_embedding, link_embedding])\n",
    "    \n",
    "    # Reshape to be a single number (shape will be (None, 1))\n",
    "    merged = Reshape(target_shape = [1])(merged)\n",
    "    \n",
    "    # Squash outputs for classification\n",
    "    out = Dense(1, activation = 'sigmoid')(merged)\n",
    "    model = Model(inputs = [asin, link], outputs = out)\n",
    "    \n",
    "    # Compile using specified optimizer and loss \n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "asin (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "link (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "asin_embedding (Embedding)      (None, 1, 50)        389200      asin[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (Embedding)      (None, 1, 50)        760600      link[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           asin_embedding[0][0]             \n",
      "                                                                 link_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            2           reshape_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,149,802\n",
      "Trainable params: 1,149,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "def find_similar(name, weights, index_name = 'asin', n = 10, least = False, return_dist = False, plot = False):\n",
    "    \"\"\"Find n most similar items (or least) to name based on embeddings. Option to also plot the results\"\"\"\n",
    "    \n",
    "    # Select index and reverse index\n",
    "    if index_name == 'asin':\n",
    "        index = asin_index\n",
    "        rindex = index_asin\n",
    "    elif index_name == 'link':\n",
    "        index = link_index\n",
    "        rindex = index_link\n",
    "    \n",
    "    # Check to make sure `name` is in index\n",
    "    try:\n",
    "        # Calculate dot product between book and all others\n",
    "        dists = np.dot(weights, weights[index[name]])\n",
    "    except KeyError:\n",
    "        print(f'{name} Not Found.')\n",
    "        return\n",
    "    \n",
    "    # Sort distance indexes from smallest to largest\n",
    "    sorted_dists = np.argsort(dists)\n",
    "    \n",
    "    # Plot results if specified\n",
    "    if plot:\n",
    "        \n",
    "        # Find furthest and closest items\n",
    "        furthest = sorted_dists[:(n // 2)]\n",
    "        closest = sorted_dists[-n-1: len(dists) - 1]\n",
    "        items = [rindex[c] for c in furthest]\n",
    "        items.extend(rindex[c] for c in closest)\n",
    "        \n",
    "        # Find furthest and closets distances\n",
    "        distances = [dists[c] for c in furthest]\n",
    "        distances.extend(dists[c] for c in closest)\n",
    "        \n",
    "        colors = ['r' for _ in range(n //2)]\n",
    "        colors.extend('g' for _ in range(n))\n",
    "        \n",
    "        data = pd.DataFrame({'distance': distances}, index = items)\n",
    "        \n",
    "        # Horizontal bar chart\n",
    "        data['distance'].plot.barh(color = colors, figsize = (10, 8),\n",
    "                                   edgecolor = 'k', linewidth = 2)\n",
    "        plt.xlabel('Cosine Similarity');\n",
    "        plt.axvline(x = 0, color = 'k');\n",
    "        \n",
    "        # Formatting for italicized title\n",
    "        name_str = f'{index_name.capitalize()}s Most and Least Similar to'\n",
    "        for word in name.split():\n",
    "            # Title uses latex for italize\n",
    "            name_str += ' $\\it{' + word + '}$'\n",
    "        plt.title(name_str, x = 0.2, size = 28, y = 1.05)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # If specified, find the least similar\n",
    "    if least:\n",
    "        # Take the first n from sorted distances\n",
    "        closest = sorted_dists[:n]\n",
    "         \n",
    "        print(f'{index_name}s furthest from {asin_name[name]} ({name}).\\n')\n",
    "        \n",
    "    # Otherwise find the most similar\n",
    "    else:\n",
    "        # Take the last n sorted distances\n",
    "        closest = sorted_dists[-n:]\n",
    "        \n",
    "        # Need distances later on\n",
    "        if return_dist:\n",
    "            return dists, closest\n",
    "        \n",
    "        \n",
    "        print(f'{index_name.capitalize()}s closest to {asin_name[name]} ({name}).\\n')\n",
    "        \n",
    "    # Need distances later on\n",
    "    if return_dist:\n",
    "        return dists, closest\n",
    "    \n",
    "    \n",
    "    # Print formatting\n",
    "    max_width = max([len(rindex[c]) for c in closest])\n",
    "    \n",
    "    # Print the most similar and distances\n",
    "    for c in reversed(closest):\n",
    "        print(f'''{asin_name[rindex[c]]:{max_width + 2}} \n",
    "        {index_name.capitalize()}: {rindex[c]:{max_width + 2}} Similarity: {dists[c]:.{2}}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "73/73 [==============================] - 4s 51ms/step - loss: -6.0654 - accuracy: 0.3592\n",
      "Epoch 2/30\n",
      "46/73 [=================>............] - ETA: 1s - loss: -5.8920 - accuracy: 0.3754"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-2db8dda83357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m h = model.fit_generator(gen, epochs = epochs, \n\u001b[0;32m---> 13\u001b[0;31m                         steps_per_epoch = steps_per_epoch)\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_positive = 2**12\n",
    "epochs = 30\n",
    "negative_ratio = 1\n",
    "validation_split = 0.2\n",
    "\n",
    "gen = generate_batch(pairs, n_positive, negative_ratio = negative_ratio)\n",
    "\n",
    "steps_per_epoch = len(pairs) // n_positive\n",
    "\n",
    "\n",
    "# Train\n",
    "h = model.fit_generator(gen, epochs = epochs, \n",
    "                        steps_per_epoch = steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'models/model-n_positive-{n_positive}-epochs-{epochs}-negative_ratio-{negative_ratio}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7784, 50)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asin_layer = model.get_layer('asin_embedding')\n",
    "asin_weights = asin_layer.get_weights()[0]\n",
    "asin_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asin_weights = asin_weights / np.linalg.norm(asin_weights, axis = 1).reshape((-1, 1))\n",
    "asin_weights[0][:10]\n",
    "np.sum(np.square(asin_weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0000DIWNZ, B0000GH6UG Not Found.\n",
      "\n",
      "\n",
      "\n",
      "Asins closest to Saran Premium Plastic Wrap, 100 Sq Ft (B0000DIWNI).\n",
      "\n",
      "Saran Premium Plastic Wrap, 100 Sq Ft \n",
      "        Asin: B0000DIWNI   Similarity: 1.0\n",
      "CeraVe Hydrating Body Wash 10 oz \n",
      "        Asin: B01CTRKAQU   Similarity: 1.0\n",
      "Poise® Incontinence Pads, Maximum Absorbency, Long, 39 Count \n",
      "        Asin: B0166NBALC   Similarity: 1.0\n",
      "Neutrogena Ultra Gentle Daily Facial Cleanser for Sensitive Skin, Oil-Free, Soap-Free, Hypoallergenic & Non-Comedogenic Foaming Face Wash, 12 fl. oz \n",
      "        Asin: B00UOLD4DK   Similarity: 0.99\n",
      "Ntg Makeup Rmvr Clnsng Twlt 25s Rfl Twpk \n",
      "        Asin: B0182G7AQ0   Similarity: 0.99\n",
      "Cheez-It Baked Snack Cheese Crackers, White Cheddar, 7 oz Box \n",
      "        Asin: B013JMERZ4   Similarity: 0.99\n",
      "CeraVe Eczema Soothing Body Wash 10 oz with Omega Oils and Ceramides for Cleansing and Calming Dry, Itchy, Eczema Prone Skin \n",
      "        Asin: B01BONXOWW   Similarity: 0.98\n",
      "Health Warrior Chia Bars Variety Pack, Coconut/Acai Berry/Mango, 15 Count \n",
      "        Asin: B015EHMQNM   Similarity: 0.97\n",
      "Stacy's Parmesan Garlic & Herb Flavored Pita Chips, 7.33 Ounce \n",
      "        Asin: B013TY4W3O   Similarity: 0.96\n",
      "Aveeno Daily Moisturizing Body Wash with Soothing Oat, Creamy Shower Gel, Soap-Free and Dye-Free, Light Fragrance, 12 fl. oz \n",
      "        Asin: B00UOLAPB4   Similarity: 0.94\n",
      "\n",
      "\n",
      "\n",
      "Asins closest to HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween Candy) (B00005BPJO).\n",
      "\n",
      "HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween Candy) \n",
      "        Asin: B00005BPJO   Similarity: 1.0\n",
      "Famous Dave's Sweet and Zesty BBQ Sauce, 20 oz \n",
      "        Asin: B00MSZL8O2   Similarity: 1.0\n",
      "Wish-Bone Salad Dressing, Sweet & Spicy Honey Mustard, 16 Ounce \n",
      "        Asin: B01GCO3KDQ   Similarity: 1.0\n",
      "Made In Nature Organic Apples, 3 Oz \n",
      "        Asin: B000VK45KU   Similarity: 1.0\n",
      "Fruitocracy, Apple, 4 Count \n",
      "        Asin: B00H3SUJ4Y   Similarity: 1.0\n",
      "Loacker Quadratini Dark Chocolate Creme Wafer Cookies, 8.82 Ounce \n",
      "        Asin: B01B632QKQ   Similarity: 1.0\n",
      "Bush's Best Vegetarian Baked Beans 28 oz \n",
      "        Asin: B000RY6GMU   Similarity: 1.0\n",
      "Rosarita Vegetarian Refried Beans, 16 oz, 12 Pack \n",
      "        Asin: B000Q3FRP4   Similarity: 1.0\n",
      "SoftSheen-Carson Dark and Lovely Au Naturale Moisture LOC Sulfate-Free Cleansing Shampoil, 13.5 fl oz \n",
      "        Asin: B01487OXEY   Similarity: 1.0\n",
      "Delsym Children's DM Cough + Chest Congestion Relief Liquid, Cherry, 6oz \n",
      "        Asin: B011O32JCI   Similarity: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Asins closest to Wish-Bone Salad Dressing, Sweet & Spicy Honey Mustard, 16 Ounce (B01GCO3KDQ).\n",
      "\n",
      "Wish-Bone Salad Dressing, Sweet & Spicy Honey Mustard, 16 Ounce \n",
      "        Asin: B01GCO3KDQ   Similarity: 1.0\n",
      "Made In Nature Organic Apples, 3 Oz \n",
      "        Asin: B000VK45KU   Similarity: 1.0\n",
      "Talk O Texas Mild Pickled Okra, 16 oz \n",
      "        Asin: B00ZR2ZH90   Similarity: 1.0\n",
      "Energizer MAX D Alkaline Batteries, 4-Count \n",
      "        Asin: B000YHXX8K   Similarity: 1.0\n",
      "Karen's Naturals Just Tomatoes, Just Peas Large Pouch, 8 Ounce (Packaging May Vary) \n",
      "        Asin: B00N9BW00A   Similarity: 1.0\n",
      "Rosarita Vegetarian Refried Beans, 16 oz, 12 Pack \n",
      "        Asin: B000Q3FRP4   Similarity: 1.0\n",
      "Red Oval Farms Stoned Wheat Thin Crackers, 10.6 Ounce \n",
      "        Asin: B000S5OA8U   Similarity: 1.0\n",
      "Delsym Children's DM Cough + Chest Congestion Relief Liquid, Cherry, 6oz \n",
      "        Asin: B011O32JCI   Similarity: 1.0\n",
      "HERSHEY'S Milk Duds Candy, 5 Ounce(Halloween Candy) \n",
      "        Asin: B00005BPJO   Similarity: 1.0\n",
      "Deo Pure Antiperspirant Roll-On by Biotherm, 2.53 Ounce \n",
      "        Asin: B01CTRH8RO   Similarity: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Asins closest to Aveeno Daily Moisturizing Body Wash with Soothing Oat, Creamy Shower Gel, Soap-Free and Dye-Free, Light Fragrance, 12 fl. oz (B00UOLAPB4).\n",
      "\n",
      "Aveeno Daily Moisturizing Body Wash with Soothing Oat, Creamy Shower Gel, Soap-Free and Dye-Free, Light Fragrance, 12 fl. oz \n",
      "        Asin: B00UOLAPB4   Similarity: 1.0\n",
      "Ntg Makeup Rmvr Clnsng Twlt 25s Rfl Twpk \n",
      "        Asin: B0182G7AQ0   Similarity: 0.97\n",
      "Aveeno Pure Renewal Hair Shampoo, Moisturizing Shampoo with Seaweed Extract, Sulfate-Free Formula 10.5 fl. oz \n",
      "        Asin: B00UOLCK4E   Similarity: 0.97\n",
      "Cheez-It Baked Snack Cheese Crackers, White Cheddar, 7 oz Box \n",
      "        Asin: B013JMERZ4   Similarity: 0.97\n",
      "CeraVe Eczema Soothing Body Wash 10 oz with Omega Oils and Ceramides for Cleansing and Calming Dry, Itchy, Eczema Prone Skin \n",
      "        Asin: B01BONXOWW   Similarity: 0.96\n",
      "Poise® Incontinence Pads, Maximum Absorbency, Long, 39 Count \n",
      "        Asin: B0166NBALC   Similarity: 0.96\n",
      "Saran Premium Plastic Wrap, 100 Sq Ft \n",
      "        Asin: B0000DIWNI   Similarity: 0.94\n",
      "CeraVe Hydrating Body Wash 10 oz \n",
      "        Asin: B01CTRKAQU   Similarity: 0.93\n",
      "Neutrogena Ultra Gentle Daily Facial Cleanser for Sensitive Skin, Oil-Free, Soap-Free, Hypoallergenic & Non-Comedogenic Foaming Face Wash, 12 fl. oz \n",
      "        Asin: B00UOLD4DK   Similarity: 0.92\n",
      "Aveeno Pure Renewal  Hair Conditioner, Moisturizing Conditioner with Seaweed Extract, Sulfate-Free Formula, 10.5 fl. oz \n",
      "        Asin: B00UOLDBA6   Similarity: 0.92\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod_lst = ['B0000DIWNZ, B0000GH6UG', 'B0000DIWNI', 'B00005BPJO', 'B01GCO3KDQ', 'B00UOLAPB4']\n",
    "for prod in prod_lst:\n",
    "    find_similar(prod, asin_weights)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
